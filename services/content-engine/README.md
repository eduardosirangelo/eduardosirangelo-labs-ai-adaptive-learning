# Content Engine

Este microservi√ßo √© o cora√ß√£o do m√≥dulo de conte√∫do adaptativo da plataforma. Aqui, oferecemos li√ß√µes personalizadas e din√¢micas aos estudantes, baseado em algoritmos de AI (RAG e LLM). A seguir, descrevemos de forma did√°tica os **pr√≥ximos passos de desenvolvimento**, explicando **o que** ser√° implementado e **por que** utilizamos cada padr√£o de arquitetura e design.

## üöÄ Objetivos de Desenvolvimento

1. **Modelagem de Dom√≠nio (Entities)**

    * *O que ser√° feito:* Definir modelos puros como `Student`, `ContentItem`, `LearningPath` e `AssessmentResult`.
    * *Por que:* Isolar regras de neg√≥cio fundamentais sem acopl√°-las a frameworks ou infraestrutura, seguindo o princ√≠pio de manter o n√∫cleo da aplica√ß√£o limpo e test√°vel (Clean Architecture).

2. **Casos de Uso (Use Cases)**

    * *O que ser√° feito:* Implementar m√©todos como `GenerateAdaptivePath(studentID)` e `GetContentByID` que orquestram a l√≥gica central.
    * *Por que:* Concentrar a l√≥gica de aplica√ß√£o em uma camada espec√≠fica torna o c√≥digo mais organizado, facilita testes e respeita o Single Responsibility Principle.

3. **Interfaces de Reposit√≥rio (Ports)**

    * *O que ser√° feito:* Criar interfaces como `ContentRepository` com m√©todos `Save`, `FindByID`, `ListByCriteria`.
    * *Por que:* O Repository Pattern desacopla a l√≥gica de persist√™ncia dos casos de uso, permitindo trocar o banco (PostgreSQL, mocks em testes) sem alterar o n√∫cleo.

4. **Adaptadores de Persist√™ncia (Adapters)**

    * *O que ser√° feito:* Implementar `PostgresContentRepository` que cumpre a interface acima, usando `database/sql` ou ORM leve.
    * *Por que:* Seguir o Ports & Adapters (Hexagonal) garante que detalhes do banco n√£o vazem para o dom√≠nio.

5. **Camada de Servi√ßo (Service Layer)**

    * *O que ser√° feito:* Criar `ContentService` que recebe as depend√™ncias via construtor e aplica a l√≥gica de neg√≥cio (filtragem, regras adaptativas).
    * *Por que:* O Service Layer Pattern organiza casos de uso de forma coesa e facilita a inje√ß√£o de depend√™ncias para testes.

6. **Integra√ß√£o com LLM/RAG (Adapter + Strategy)**

    * *O que ser√° feito:* Definir interface `LLMClient` e implementar estrat√©gias (por ex., `OpenAIClient`, `LocalRAGClient`).
    * *Por que:* Adapter Pattern desacopla a API externa, e Strategy Pattern permite alternar algoritmos de gera√ß√£o de conte√∫do dinamicamente.

7. **Event-Driven com Kafka**

    * *O que ser√° feito:* Configurar produtores/consumidores para eventos `ContentRequested` e `ContentDelivered`.
    * *Por que:* A arquitetura orientada a eventos desacopla componentes e melhora escalabilidade e resili√™ncia.

8. **Exposi√ß√£o de API (REST + gRPC)**

    * *O que ser√° feito:* Usar Chi e middlewares comuns (autentica√ß√£o, logging, CORS) para expor endpoints HTTP e gRPC.
    * *Por que:* Oferecer m√∫ltiplas interfaces de consumo e manter consist√™ncia de cross-cutting concerns via pkg/http e pkg/auth.

9. **Resili√™ncia (Circuit Breaker & Retry)**

    * *O que ser√° feito:* Aplicar pol√≠ticas de retry e circuit breaker nas chamadas externas (LLM, DB).
    * *Por que:* Prevenir falhas em cascata e garantir robustez em produ√ß√£o.

10. **Testes Automatizados**

    * *O que ser√° feito:* Escrever testes de unidade nas camadas Domain e Service, e testes de integra√ß√£o para adaptadores.
    * *Por que:* Validar regras de neg√≥cio isoladamente e garantir que a aplica√ß√£o funcione conforme esperado em diferentes cen√°rios.

## üìö Por que esta abordagem?

Toda a evolu√ß√£o do Content Engine segue os princ√≠pios da **Clean Architecture** e dos **Design Patterns** selecionados para:

* **Separar responsabilidades** (Single Responsibility Principle)
* **Isolar regras de neg√≥cio** de frameworks e infraestrutura
* **Facilitar testes** unit√°rios e de integra√ß√£o
* **Promover reuso** de c√≥digo e padr√µes consistentes entre microservi√ßos
* **Garantir escalabilidade e manuten√ß√£o** a longo prazo

Com este roadmap, o estudante compreender√° n√£o apenas **o que** implementar, mas **por que** cada decis√£o arquitetural e de design pattern foi tomada, preparando-o para construir sistemas sofisticados e profissionais.

### üì¶ Estrutura do Reposit√≥rio

```plaintext
services/content-engine/
‚îú‚îÄ‚îÄ cmd/
‚îÇ   ‚îî‚îÄ‚îÄ content-engine/      # main.go inicializa√ß√£o do servi√ßo
‚îÇ
‚îú‚îÄ‚îÄ internal/
‚îÇ   ‚îú‚îÄ‚îÄ domain/              # defini√ß√µes de entidades (structs)
‚îÇ   ‚îú‚îÄ‚îÄ service/             # casos de uso / regras de neg√≥cio
‚îÇ   ‚îî‚îÄ‚îÄ repository/          # interface e implementa√ß√£o de acesso a dados
‚îÇ
‚îú‚îÄ‚îÄ pkg/                     # helpers ou libs que podem ser exportadas
‚îÇ
‚îî‚îÄ‚îÄ go.mod
```

## üìñ Como usar este servi√ßo

Para testar e explorar o Content Engine:

1. **Clone o reposit√≥rio e sincronize o workspace Go**

   ```bash
   git clone git@github.com:eduardosirangelo/ai-adaptive-learning.git
   cd ai-adaptive-learning
   go work sync
   ```
2. **Configure vari√°veis de ambiente (exemplo local)**

   ```bash
   export PORT=8070
   export DATABASE_URL="postgres://user:pass@localhost:5432/contentdb"
   export KAFKA_BROKERS=localhost:9092
   ```
3. **Ingressar no servi√ßo**

   ```bash
   cd services/content-engine
   go run cmd/content-engine/main.go
   ```
4. **Verificar health check**

   ```bash
   curl http://localhost:8070/health
   # deve retornar "OK"
   ```

## üîó Documenta√ß√£o e Cole√ß√£o Postman / gRPC & Queue Tests

* **API REST (Postman Collection)**: importe esta cole√ß√£o p√∫blica no Postman para visualizar e testar todos os endpoints REST do Content Engine:
  [https://www.postman.com/eduardosirangelo/workspace/ai-adaptive-learning-engine/collection/CONTENT-ENGINE](https://www.postman.com/eduardosirangelo/workspace/ai-adaptive-learning-engine/collection/CONTENT-ENGINE)

* **gRPC & Event-Driven (Queue) Tests**:

    * Use `grpcurl` ou Postman gRPC para invocar m√©todos gRPC definidos em `services/content-engine/api.proto`.
    * Consuma e produza eventos Kafka usando scripts em `services/content-engine/tools/kafka-cli.sh`, verificando t√≥picos `content.requested` e `content.delivered`.

---

## English Version

# Content Engine

This microservice is the heart of the platform's adaptive content module. It delivers personalized, dynamic lessons to students using AI algorithms (RAG and LLM). Below we describe in a didactic way the **next development steps**, explaining **what** will be implemented and **why** each architectural and design pattern was chosen.

## üöÄ Development Goals

1. **Domain Modeling (Entities)**

    * *What will be done:* Define pure domain models such as `Student`, `ContentItem`, `LearningPath`, and `AssessmentResult`.
    * *Why:* To isolate core business rules from frameworks or infrastructure, keeping the application core clean and testable (Clean Architecture).

2. **Use Cases**

    * *What will be done:* Implement methods like `GenerateAdaptivePath(studentID)` and `GetContentByID` that orchestrate core logic.
    * *Why:* Concentrating application logic in a specific layer makes code more organized, easier to test, and aligns with the Single Responsibility Principle.

3. **Repository Interfaces (Ports)**

    * *What will be done:* Create interfaces like `ContentRepository` with methods `Save`, `FindByID`, `ListByCriteria`.
    * *Why:* The Repository Pattern decouples persistence logic from use cases, allowing swapping out the database (PostgreSQL, mock in tests) without modifying the core logic.

4. **Persistence Adapters**

    * *What will be done:* Implement `PostgresContentRepository` fulfilling the above interface, using `database/sql` or a lightweight ORM.
    * *Why:* Following Ports & Adapters (Hexagonal) ensures that database details do not leak into the domain layer.

5. **Service Layer**

    * *What will be done:* Create `ContentService` that receives dependencies via constructor and applies business logic (filtering, adaptive rules).
    * *Why:* The Service Layer Pattern organizes use cases cohesively and facilitates dependency injection for testing.

6. **LLM/RAG Integration (Adapter + Strategy)**

    * *What will be done:* Define an `LLMClient` interface and implement strategies (e.g., `OpenAIClient`, `LocalRAGClient`).
    * *Why:* Adapter Pattern decouples external API details, and Strategy Pattern allows dynamic switching between content generation algorithms.

7. **Event-Driven with Kafka**

    * *What will be done:* Configure producers/consumers for `ContentRequested` and `ContentDelivered` events.
    * *Why:* Event-driven architecture decouples components and improves scalability and resilience.

8. **API Exposure (REST + gRPC)**

    * *What will be done:* Use Chi and shared middlewares (authentication, logging, CORS) to expose HTTP and gRPC endpoints.
    * *Why:* Provide multiple consumption interfaces and maintain consistency of cross-cutting concerns via pkg/http and pkg/auth.

9. **Resilience (Circuit Breaker & Retry)**

    * *What will be done:* Apply retry and circuit breaker policies on external calls (LLM, DB).
    * *Why:* Prevent cascading failures and ensure robustness in production.

10. **Automated Testing**

    * *What will be done:* Write unit tests for Domain and Service layers and integration tests for adapters.
    * *Why:* Validate business rules in isolation and ensure the application behaves as expected in various scenarios.

## üìö Why This Approach?

The Content Engine's evolution follows **Clean Architecture** principles and carefully selected **Design Patterns** to:

* **Separate responsibilities** (Single Responsibility Principle)
* **Isolate business rules** from frameworks and infrastructure
* **Facilitate** unit and integration testing
* **Promote code reuse** and consistent patterns across microservices
* **Ensure long-term scalability and maintainability**

This roadmap helps learners grasp not just **what** to implement, but **why** each architectural and design decision was made, preparing them to build sophisticated, professional systems.

### üì¶ Repository Structure

```plaintext
services/content-engine/
‚îú‚îÄ‚îÄ cmd/
‚îÇ   ‚îî‚îÄ‚îÄ content-engine/      # main.go and server initialization
‚îÇ
‚îú‚îÄ‚îÄ internal/
‚îÇ   ‚îú‚îÄ‚îÄ domain/              # entity definitions (structs)
‚îÇ   ‚îú‚îÄ‚îÄ service/             # use cases / business rules
‚îÇ   ‚îî‚îÄ‚îÄ repository/          # data access interface and implementation
‚îÇ
‚îú‚îÄ‚îÄ pkg/                     # helpers or libs that can be exported
‚îÇ
‚îî‚îÄ‚îÄ go.mod
```

## üìñ How to Use this Service

To test and explore the Content Engine:

1. **Clone the repository and sync the Go workspace**

   ```bash
   git clone git@github.com:eduardosirangelo/ai-adaptive-learning.git
   cd ai-adaptive-learning
   go work sync
   ```
2. **Set environment variables (local example)**

   ```bash
   export PORT=8070
   export DATABASE_URL="postgres://user:pass@localhost:5432/contentdb"
   export KAFKA_BROKERS=localhost:9092
   ```
3. **Run the service**

   ```bash
   cd services/content-engine
   go run cmd/content-engine/main.go
   ```
4. **Check health endpoint**

   ```bash
   curl http://localhost:8070/health
   # should return "OK"
   ```

## üîó Documentation & Test Collections

* **REST API (Postman Collection)**: Import the public collection in Postman to view and test all Content Engine REST endpoints:
  [https://www.postman.com/eduardosirangelo/workspace/ai-adaptive-learning-engine/collection/CONTENT-ENGINE](https://www.postman.com/eduardosirangelo/workspace/ai-adaptive-learning-engine/collection/CONTENT-ENGINE)

* **gRPC & Event-Driven (Queue) Tests**:

    * Use `grpcurl` or Postman gRPC to invoke methods defined in `services/content-engine/api.proto`.
    * Produce and consume Kafka events using scripts in `services/content-engine/tools/kafka-cli.sh`, monitoring topics `content.requested` and `content.delivered`.


# Content Engine

This microservice in Go is responsible for:
- Generating and delivering adaptive content to students.
- Exposing REST endpoints (e.g., `GET /content/{studentId}`) that return personalized lessons.
- Integrating with the RAG/LLM mechanism to search and compose material.



## How to run

```bash
  cd services/content-engine
```
```bash
  docker build -t content-engine .
```
```bash
  docker run --network aal_engine_network content-engine
```

## Next steps
- Add `PostgreSQL` schema migrations.
- Implement request caching using `Redis`.
